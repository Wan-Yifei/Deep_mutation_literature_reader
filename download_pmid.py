import csv, urllib
import os, sys, time
from bs4 import BeautifulSoup

def read_pmid_doi(input_file_pmid):
    '''
    Read pmid-doi paris from input CSV generated by extract_pmid_doi.py
    :param input_file_pmid;
    :return pmids_doi: list includes all pmids.
    '''
    with open(input_file_pmid, "r", encoding="utf-8") as csvfile:
        raw = csv.reader(csvfile, delimiter = ",")
        header = next(raw)
        header = [colname.lower() for colname in header]
        pmid_ind = header.index("pmid")
        doi_ind = header.index("doi")
        pmids_doi = {row[pmid_ind]: row[doi_ind] for row in raw}
    return pmids_doi

def make_pmid_checkdict(pmids_doi):
    '''
    Make a dict to record the download status.
    Default value is zero which means not downloaded yet.
    One means downloaded.
    :param pmids: pmid lists;
    :return: pmid_checkdict.
    '''
    pass

def liter_status_check(pmids_doi, literature_folder):
    '''
    Check whether literatures are downloaded already.
    If yes, update the status to ok.
    :param pmid_checkdict: key - pmid, value - download status;
    :param literature_folder: parient pathway of literatures;
    :return: pmid_checkdict.
    '''
    pmid_checkdict = {pmid: "status unknown" for pmid in pmids_doi.keys()} ## duplicate pmid would be removed
    for pmid in pmid_checkdict.keys():
        if os.path.isfile("{}/{}.pdf".format(literature_folder, pmid)):
            pmid_checkdict[pmid] = "ok"
    return pmid_checkdict

def get_pdf_url(doi, attempts_limit = 3, sleep_between_tries = 60):
    '''
    Obtain url of pdf file from Sci-Hub.
    :param doi: DOI of literatures;
    :param sleep_between_retries: sleep times bwtween get PDF URL attempts;
    :return: pdf url.
    '''
    scihub_root = "https://sci-hub.se/"  ## url of scihub_root with an additional slash
    url = scihub_root + doi
    print("Try to fetch PDF URL of DOI: {}".format(doi))
    print("From URL: {}".format(url))
    attempts = 0
    while attempts < attempts_limit:
        attempts += 1
        try:
            print("Get PDF URL attempt {}".format(attempts))
            response = urllib.request.urlopen(url)
            response = response.read()
            soup = BeautifulSoup(response, features="html.parser")
            pdf_url = soup.find("embed", attrs={"type": "application/pdf", "id": "pdf"})["src"]  ## get url of pdf
            if pdf_url.startswith('//'):
                pdf_url = pdf_url[2:]
                pdf_url = 'https://' + pdf_url
            print("Got the PDF URL!")
            break
        except Exception:
            print("Get PDF url of DOI: {} failed!!".format(doi))
            print("Sleep {} seconds before retry!\n".format(sleep_between_tries))
            pdf_url = None
            if attempts < attempts_limit:
                time.sleep(sleep_between_tries)
    if not pdf_url:
        print("Did not find PDF url of DOI {}, set URL as None!!\n".format(doi))
        return pdf_url
    return pdf_url

def down_literature(pmids_doi, pmid_checkdict, literature_folder, attempts_limit = 3, sleep_between_get_url = 10, sleep_between_tries = 5):
    '''
    Downlaod PDF literature from Sci-Hub accordin to the DOI.
    :param pmids_doi: the dictionary key -> pmid / value -> doi;
    :param pmid_checkdict: the dictionary key -> pmid / value -> status;
    :param literature_folder: folder path of downloaded PDFs;
    :param attempts_limit: maximus retries times;
    :param sleep_between_get_url: sleep times between get PDF URL attempts;
    :param sleep_between_retries: sleep times bwtween download PDF URL attempts;
    :return: None.
    '''
    print("Begin to download...\n")
    for pmid in pmid_checkdict.keys():
        doi = pmids_doi[pmid]
        if pmid_checkdict[pmid] == "ok":
            print("PMID: {} already exists, skip!\n".format(pmid))
            continue
        if doi:
            pdf_url = get_pdf_url(doi) ## Try to get PDF source URL from Sci-Hub
            time.sleep(sleep_between_get_url)
            if not pdf_url:
                pmid_checkdict[pmid] = "PDF url not found"
                print("PMID: {} does not have PDF URL!".format(pmid))
                continue
            attempts = 0
            while attempts < attempts_limit:
                attempts += 1
                try:
                    print("Download attempt {}".format(attempts))
                    pdf = urllib.request.urlopen(pdf_url)
                    reason = pdf.reason
                    pdf = pdf.read()
                    pdf_output = literature_folder + "/" + pmid + ".pdf"
                    with open(pdf_output, "wb") as output:
                        output.write(pdf)
                    print("PMID: {} has been downloaded!\n".format(pmid))
                    pmid_checkdict[pmid] =reason
                    break
                except:
                    print("Error: Download of PMID {} failed!!".format(pmid))
                    print("Sleep before retry: {} seconds".format(sleep_between_tries))
                    time.sleep(sleep_between_tries)
                finally:
                    pmid_checkdict[pmid] = reason

def write_download_log(pmid_checkdict, literature_folder):
    with open(literature_folder + "/download_log.csv", "w", newline="") as log:
        log_writer = csv.writer(log)
        log_writer.writerow(["PMID", "Status"])
        for pmid, status in pmid_checkdict.items():
            log_writer.writerow([pmid, status])

def pmid_doi_summary(pmids_doi):
    '''
    Summrize the count of PMIDs/DOIs.
    :param pmids_doi: dict of pmids-doi, key -> pmid, value -> doi;
    :return: None.
    '''
    print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
    print("Summary of PMID-DOI source file:\n")
    print("Total # pmids: {}".format(len(pmids_doi)))
    count_dois = set(pmids_doi.values())
    count_dois.remove("")
    print("Total # doi: {}".format(len(count_dois)))
    print("<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n")

def download_summary(pmid_checkdict):
    '''
    Summrize the status of download process.
    :param pmid_checkdict: dict of pmid-status, key -> pmid, value -> status;
    :return: None
    '''
    status_set = set([status.lower() for status in pmid_checkdict.values()])
    status_list = list(pmid_checkdict.values())
    print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
    print("Summary of literature status:\n")
    for status in status_set:
        print("Count # of {}: {}".format(status, status_list.count(status)))
    print("<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n")

def main():
    input_file_pmid = sys.argv[1]
    literature_folder = sys.argv[2]
    pmids_doi = read_pmid_doi(input_file_pmid)
    pmid_checkdict = liter_status_check(pmids_doi, literature_folder)
    try:
        down_literature(pmids_doi, pmid_checkdict, literature_folder)
    except:
        pass
    finally:
        pmid_doi_summary(pmids_doi)
        download_summary(pmid_checkdict)
        write_download_log(pmid_checkdict, literature_folder)

if __name__ == '__main__':
    main()
